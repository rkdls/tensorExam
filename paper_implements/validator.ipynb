{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import datetime\n",
    "from glob import iglob\n",
    "import time\n",
    "# import attention\n",
    "from collections import deque\n",
    "import pickle\n",
    "from BeamSearchTree import BeamSearchTreeNode\n",
    "import pyreader\n",
    "import numpy as np\n",
    "from attention import Batcher, construct_feed_dict, extract_results, get_evals,AttentionModel,get_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_path(tree, k=1):\n",
    "\n",
    "    paths = []\n",
    "\n",
    "    def search_tree(path, node, path_prob):\n",
    "        if not node.children:\n",
    "            paths.append((path, path_prob))\n",
    "        else:\n",
    "            for child in node.children:\n",
    "                search_tree(path + [child.token_id], child, path_prob + np.log(child.probability))\n",
    "\n",
    "    search_tree([], tree, 0)\n",
    "\n",
    "    sorted_paths = sorted(paths, key=lambda x: x[1], reverse=True)\n",
    "    return [path[0] for path in sorted_paths[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type_max_rands = {\n",
    "    \"var\": 4750, \"function\": 2900, \"Class\": 440, \"attribute\": 2400, \"arg\": 2400\n",
    "}\n",
    "def map_token(map, token):\n",
    "    mask = 0\n",
    "    if token.startswith(\"(*) \"):\n",
    "        mask = 1\n",
    "        token = token.replace(\"(*) \", \"\")\n",
    "\n",
    "    if token in map:\n",
    "        return map[token], mask\n",
    "\n",
    "    # Not in map, is it an identifier?\n",
    "    if \"|\" in token:\n",
    "        spl = token.split(\"|\")\n",
    "        if spl[1] in map:\n",
    "            return map[spl[1]]\n",
    "        elif spl[0] in map:\n",
    "            return map[spl[0]]\n",
    "        return pyreader.oov_id\n",
    "\n",
    "    elif any([token.startswith(prefix) for prefix in [key for key in type_max_rands]]):\n",
    "        return pyreader.oov_id\n",
    "\n",
    "    raise KeyError(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 1\n",
    "batch_size = 1\n",
    "hidden_size = 50\n",
    "num_samples = 3\n",
    "lambda_type='state'\n",
    "max_attention=3\n",
    "model_path = './model/2017-07-01--01-22--006942'\n",
    "data_path='data_samples/mapping.map'\n",
    "with open(data_path, \"rb\") as f:\n",
    "    word_to_id = pickle.load(f)\n",
    "vocab_size = len(word_to_id)\n",
    "inv_map = {v: k for k, v in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_test_cases = [\"import\", \"os\", \"\\n\", \"class\", \"(*) Class291\", \":\", \"\\n\", \"§<indent>§\", \"def\", \"__init__\", \"(\", \"self\", \",\",\n",
    "     \"(*) arg123\", \")\", \":\", \"\\n\", \"§<indent>§\", \"self\", \".\", \"(*) attribute|attribute172\", \"=\", \"arg123\", \"\\n\", \"\\n\",\n",
    "     \"§<dedent>§\",\n",
    "     \"def\", \"(*) function234\", \"(\", \"self\", \",\", \"(*) filename|arg432\", \")\", \":\", \"\\n\", \"§<indent>§\", \"with\", \"open\",\n",
    "     \"(\", \"filename|arg432\", \",\", \"'r'\", \")\", \"as\", \"(*) f|var76\", \":\", \"\\n\", \"§<indent>§\", \"(*) lines|var91\", \"=\",\n",
    "     \"f|var76\", \".\",\n",
    "     \"readlines\", \"(\", \")\", \"\\n\", \"§<dedent>§\", \"return\", \"len\", \"(\", \"lines|var91\", \")\", \"\\n\", \"\\n\", \"§<dedent>§\",\n",
    "     \"def\", \"(*) func|function921\", \"(\", \"self\", \",\", \"(*) arg191\", \")\", \":\", \"\\n\", \"§<indent>§\", \"(*) var543\", \"=\",\n",
    "     \"os\", \".\", \"path\", \".\", \"join\", \"(\", \"self\", \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Attention Cell\n",
      "INFO:tensorflow:Restoring parameters from ./model/2017-07-01--01-22--006942\\model.tf\n",
      "----------------------------------------\n",
      "Token(input):  import\n",
      "Predicted:  . §PAD§ . . §PAD§\n",
      "Actual   :  os <newline> class Class291 :\n",
      "----------------------------------------\n",
      "Token(input):  os\n",
      "Predicted:  §PAD§ <newline> <newline> <newline> <newline>\n",
      "Actual   :  <newline> class Class291 : <newline>\n",
      "----------------------------------------\n",
      "Token(input):  <newline>\n",
      "Predicted:  . . §PAD§ = =\n",
      "Actual   :  class Class291 : <newline> §<indent>§\n",
      "----------------------------------------\n",
      "Token(input):  class\n",
      "Predicted:  §PAD§ <newline> <newline> <newline> <newline>\n",
      "Actual   :  Class291 : <newline> §<indent>§ def\n",
      "----------------------------------------\n",
      "Token(input):  (*) Class291\n",
      "Predicted:  . . §PAD§ = §OOV§\n",
      "Actual   :  : <newline> §<indent>§ def __init__\n",
      "----------------------------------------\n",
      "Token(input):  :\n",
      "Predicted:  §OOV§ <newline> <newline> <newline> <newline>\n",
      "Actual   :  <newline> §<indent>§ def __init__ (\n",
      "----------------------------------------\n",
      "Token(input):  <newline>\n",
      "Predicted:  . . §PAD§ <newline> §PAD§\n",
      "Actual   :  §<indent>§ def __init__ ( self\n",
      "----------------------------------------\n",
      "Token(input):  §<indent>§\n",
      "Predicted:  . §OOV§ §OOV§ <newline> <newline>\n",
      "Actual   :  def __init__ ( self ,\n",
      "----------------------------------------\n",
      "Token(input):  def\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  __init__ ( self , §OOV§\n",
      "----------------------------------------\n",
      "Token(input):  __init__\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  ( self , §OOV§ )\n",
      "----------------------------------------\n",
      "Token(input):  (\n",
      "Predicted:  §OOV§ §PAD§ <newline> <newline> <newline>\n",
      "Actual   :  self , §OOV§ ) :\n",
      "----------------------------------------\n",
      "Token(input):  self\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  , §OOV§ ) : <newline>\n",
      "----------------------------------------\n",
      "Token(input):  ,\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  §OOV§ ) : <newline> §<indent>§\n",
      "----------------------------------------\n",
      "Token(input):  (*) arg123\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  ) : <newline> §<indent>§ self\n",
      "----------------------------------------\n",
      "Token(input):  )\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  : <newline> §<indent>§ self .\n",
      "----------------------------------------\n",
      "Token(input):  :\n",
      "Predicted:  self ) ) ) )\n",
      "Actual   :  <newline> §<indent>§ self . §OOV§\n",
      "----------------------------------------\n",
      "Token(input):  <newline>\n",
      "Predicted:  self . . §PAD§ =\n",
      "Actual   :  §<indent>§ self . §OOV§ =\n",
      "----------------------------------------\n",
      "Token(input):  §<indent>§\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  self . §OOV§ = §OOV§\n",
      "----------------------------------------\n",
      "Token(input):  self\n",
      "Predicted:  §OOV§ ) ) <newline> <newline>\n",
      "Actual   :  . §OOV§ = §OOV§ <newline>\n",
      "----------------------------------------\n",
      "Token(input):  .\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  §OOV§ = §OOV§ <newline> <newline>\n",
      "----------------------------------------\n",
      "Token(input):  (*) attribute|attribute172\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  = §OOV§ <newline> <newline> §<dedent>§\n",
      "----------------------------------------\n",
      "Token(input):  =\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  §OOV§ <newline> <newline> §<dedent>§ def\n",
      "----------------------------------------\n",
      "Token(input):  arg123\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  <newline> <newline> §<dedent>§ def function234\n",
      "----------------------------------------\n",
      "Token(input):  <newline>\n",
      "Predicted:  §PAD§ <newline> <newline> <newline> <newline>\n",
      "Actual   :  <newline> §<dedent>§ def function234 (\n",
      "----------------------------------------\n",
      "Token(input):  <newline>\n",
      "Predicted:  self = = §PAD§ ,\n",
      "Actual   :  §<dedent>§ def function234 ( self\n",
      "----------------------------------------\n",
      "Token(input):  §<dedent>§\n",
      "Predicted:  self . . §PAD§ <newline>\n",
      "Actual   :  def function234 ( self ,\n",
      "----------------------------------------\n",
      "Token(input):  def\n",
      "Predicted:  self = §OOV§ ) )\n",
      "Actual   :  function234 ( self , arg432\n",
      "----------------------------------------\n",
      "Token(input):  (*) function234\n",
      "Predicted:  . §OOV§ ) <newline> §PAD§\n",
      "Actual   :  ( self , arg432 )\n",
      "----------------------------------------\n",
      "Token(input):  (\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  self , arg432 ) :\n",
      "----------------------------------------\n",
      "Token(input):  self\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  , arg432 ) : <newline>\n",
      "----------------------------------------\n",
      "Token(input):  ,\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  arg432 ) : <newline> §<indent>§\n",
      "----------------------------------------\n",
      "Token(input):  (*) filename|arg432\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  ) : <newline> §<indent>§ with\n",
      "----------------------------------------\n",
      "Token(input):  )\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  : <newline> §<indent>§ with open\n",
      "----------------------------------------\n",
      "Token(input):  :\n",
      "Predicted:  self ) ) <newline> <newline>\n",
      "Actual   :  <newline> §<indent>§ with open (\n",
      "----------------------------------------\n",
      "Token(input):  <newline>\n",
      "Predicted:  self . . §PAD§ =\n",
      "Actual   :  §<indent>§ with open ( arg432\n",
      "----------------------------------------\n",
      "Token(input):  §<indent>§\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  with open ( arg432 ,\n",
      "----------------------------------------\n",
      "Token(input):  with\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  open ( arg432 , 'r'\n",
      "----------------------------------------\n",
      "Token(input):  open\n",
      "Predicted:  . . §OOV§ §PAD§ <newline>\n",
      "Actual   :  ( arg432 , 'r' )\n",
      "----------------------------------------\n",
      "Token(input):  (\n",
      "Predicted:  §OOV§ §PAD§ <newline> <newline> <newline>\n",
      "Actual   :  arg432 , 'r' ) as\n",
      "----------------------------------------\n",
      "Token(input):  filename|arg432\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  , 'r' ) as var76\n",
      "----------------------------------------\n",
      "Token(input):  ,\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  'r' ) as var76 :\n",
      "----------------------------------------\n",
      "Token(input):  'r'\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  ) as var76 : <newline>\n",
      "----------------------------------------\n",
      "Token(input):  )\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  as var76 : <newline> §<indent>§\n",
      "----------------------------------------\n",
      "Token(input):  as\n",
      "Predicted:  §OOV§ §PAD§ <newline> <newline> <newline>\n",
      "Actual   :  var76 : <newline> §<indent>§ §OOV§\n",
      "----------------------------------------\n",
      "Token(input):  (*) f|var76\n",
      "Predicted:  §PAD§ ) ) <newline> <newline>\n",
      "Actual   :  : <newline> §<indent>§ §OOV§ =\n",
      "----------------------------------------\n",
      "Token(input):  :\n",
      "Predicted:  self ) ) §PAD§ <newline>\n",
      "Actual   :  <newline> §<indent>§ §OOV§ = var76\n",
      "----------------------------------------\n",
      "Token(input):  <newline>\n",
      "Predicted:  self . . §PAD§ =\n",
      "Actual   :  §<indent>§ §OOV§ = var76 .\n",
      "----------------------------------------\n",
      "Token(input):  §<indent>§\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  §OOV§ = var76 . readlines\n",
      "----------------------------------------\n",
      "Token(input):  (*) lines|var91\n",
      "Predicted:  self = = §PAD§ ,\n",
      "Actual   :  = var76 . readlines (\n",
      "----------------------------------------\n",
      "Token(input):  =\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  var76 . readlines ( )\n",
      "----------------------------------------\n",
      "Token(input):  f|var76\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  . readlines ( ) <newline>\n",
      "----------------------------------------\n",
      "Token(input):  .\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  readlines ( ) <newline> §<dedent>§\n",
      "----------------------------------------\n",
      "Token(input):  readlines\n",
      "Predicted:  . §PAD§ ) <newline> §PAD§\n",
      "Actual   :  ( ) <newline> §<dedent>§ return\n",
      "----------------------------------------\n",
      "Token(input):  (\n",
      "Predicted:  §OOV§ §PAD§ <newline> <newline> <newline>\n",
      "Actual   :  ) <newline> §<dedent>§ return len\n",
      "----------------------------------------\n",
      "Token(input):  )\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  <newline> §<dedent>§ return len (\n",
      "----------------------------------------\n",
      "Token(input):  <newline>\n",
      "Predicted:  §PAD§ <newline> <newline> <newline> <newline>\n",
      "Actual   :  §<dedent>§ return len ( §OOV§\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Token(input):  §<dedent>§\n",
      "Predicted:  self = = §PAD§ ,\n",
      "Actual   :  return len ( §OOV§ )\n",
      "----------------------------------------\n",
      "Token(input):  return\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  len ( §OOV§ ) <newline>\n",
      "----------------------------------------\n",
      "Token(input):  len\n",
      "Predicted:  . §OOV§ ) <newline> §PAD§\n",
      "Actual   :  ( §OOV§ ) <newline> <newline>\n",
      "----------------------------------------\n",
      "Token(input):  (\n",
      "Predicted:  §OOV§ §PAD§ <newline> <newline> <newline>\n",
      "Actual   :  §OOV§ ) <newline> <newline> §<dedent>§\n",
      "----------------------------------------\n",
      "Token(input):  lines|var91\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  ) <newline> <newline> §<dedent>§ def\n",
      "----------------------------------------\n",
      "Token(input):  )\n",
      "Predicted:  self ) <newline> §PAD§ <newline>\n",
      "Actual   :  <newline> <newline> §<dedent>§ def function921\n",
      "----------------------------------------\n",
      "Token(input):  <newline>\n",
      "Predicted:  §PAD§ <newline> <newline> <newline> <newline>\n",
      "Actual   :  <newline> §<dedent>§ def function921 (\n",
      "----------------------------------------\n",
      "Token(input):  <newline>\n",
      "Predicted:  self = = §PAD§ ,\n",
      "Actual   :  §<dedent>§ def function921 ( self\n",
      "----------------------------------------\n",
      "Token(input):  §<dedent>§\n",
      "Predicted:  self . . §PAD§ <newline>\n",
      "Actual   :  def function921 ( self ,\n",
      "----------------------------------------\n",
      "Token(input):  def\n",
      "Predicted:  self = §OOV§ ) )\n",
      "Actual   :  function921 ( self , arg191\n",
      "----------------------------------------\n",
      "Token(input):  (*) func|function921\n",
      "Predicted:  . §OOV§ ) <newline> §PAD§\n",
      "Actual   :  ( self , arg191 )\n",
      "----------------------------------------\n",
      "Token(input):  (\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  self , arg191 ) :\n",
      "----------------------------------------\n",
      "Token(input):  self\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  , arg191 ) : <newline>\n",
      "----------------------------------------\n",
      "Token(input):  ,\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  arg191 ) : <newline> §<indent>§\n",
      "----------------------------------------\n",
      "Token(input):  (*) arg191\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  ) : <newline> §<indent>§ var543\n",
      "----------------------------------------\n",
      "Token(input):  )\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  : <newline> §<indent>§ var543 =\n",
      "----------------------------------------\n",
      "Token(input):  :\n",
      "Predicted:  self ) ) <newline> <newline>\n",
      "Actual   :  <newline> §<indent>§ var543 = os\n",
      "----------------------------------------\n",
      "Token(input):  <newline>\n",
      "Predicted:  self . . §PAD§ =\n",
      "Actual   :  §<indent>§ var543 = os .\n",
      "----------------------------------------\n",
      "Token(input):  §<indent>§\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  var543 = os . path\n",
      "----------------------------------------\n",
      "Token(input):  (*) var543\n",
      "Predicted:  self ) <newline> <newline> <newline>\n",
      "Actual   :  = os . path .\n",
      "----------------------------------------\n",
      "Token(input):  =\n",
      "Predicted:  §OOV§ ) <newline> self self\n",
      "Actual   :  os . path . join\n",
      "----------------------------------------\n",
      "Token(input):  os\n",
      "Predicted:  §OOV§ ) ) <newline> §PAD§\n",
      "Actual   :  . path . join (\n",
      "----------------------------------------\n",
      "Token(input):  .\n",
      "Predicted:  . §OOV§ §PAD§ <newline> <newline>\n",
      "Actual   :  path . join ( self\n",
      "----------------------------------------\n",
      "Token(input):  path\n",
      "Predicted:  . §PAD§ ) <newline> §PAD§\n",
      "Actual   :  . join ( self .\n",
      "Accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    masks_ = tf.placeholder(tf.bool, [seq_length, batch_size, 1], name=\"masks\")\n",
    "    input_data_ = tf.placeholder(tf.int32, [seq_length, batch_size], name=\"inputs\")\n",
    "    targets_ = tf.placeholder(tf.float32, [seq_length, batch_size], name=\"targets\")\n",
    "    \n",
    "    a = AttentionModel(input_data=input_data_,\n",
    "                                 targets=targets_,\n",
    "                                 masks=masks_,\n",
    "                                 is_training=False,\n",
    "                                 attention_num= 1,\n",
    "                                 batch_size=batch_size,\n",
    "                                 hidden_size=hidden_size,\n",
    "                                 num_samples=num_samples,\n",
    "                                 seq_length=seq_length,\n",
    "                                 vocab_size=vocab_size,\n",
    "                                 lambda_type=lambda_type,\n",
    "                                 max_attention=max_attention)\n",
    "    \n",
    "    \n",
    "    variables = tf.trainable_variables()\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver(variables)\n",
    "    saver.restore(session, os.path.join(model_path, \"model.tf\"))\n",
    "    \n",
    "    prediction_op = tf.nn.top_k(a.predict, 5)\n",
    "    \n",
    "    to_eval = [prediction_op[0], prediction_op[1]]\n",
    "    evaluation = get_evals(to_eval, a)\n",
    "    \n",
    "    \n",
    "    def run_network(token_id, state, att_states, att_ids, att_counts):\n",
    "        att_mask = np.ones([1, 1])\n",
    "        if isinstance(token_id, tuple):\n",
    "            data = (np.array([[token_id[0]]]), np.array([[1]]), np.array([att_mask]), np.array([1]), np.array([1]))\n",
    "        else:\n",
    "            data = (np.array([[token_id]]), np.array([[1]]), np.array([att_mask]), np.array([1]), np.array([1]))\n",
    "        feed_dict, _ = construct_feed_dict(a, data, state, att_states, att_ids, att_counts)\n",
    "\n",
    "        results = session.run(evaluation, feed_dict)\n",
    "        results, state, att_states, att_ids, alpha_states, att_counts, _ = extract_results(results, evaluation, 2,\n",
    "                                                                                           a)\n",
    "        return results, state, att_states, att_counts\n",
    "\n",
    "    def beam(tree_node):\n",
    "        # Populate the children of tree_node\n",
    "        init_state, init_att_states, init_att_counts = tree_node.state\n",
    "        results, state, att_states, att_counts = run_network(tree_node.token_id, init_state, init_att_states,\n",
    "                                                             att_ids, init_att_counts)\n",
    "        probs = results[0]\n",
    "        predict_ids = results[1]\n",
    "        for i in range(1,5):\n",
    "            tree_node.add_child(BeamSearchTreeNode(predict_ids[0, i],np.ones([1, 1]),\n",
    "                                                   (state, att_states, att_counts), probs[0, i]))\n",
    "\n",
    "    def beam_search_recursive(tree, current_depth):\n",
    "        if current_depth < 5:\n",
    "            for child in tree.children:\n",
    "                beam(child)\n",
    "                beam_search_recursive(child, current_depth + 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    state, att_states, att_ids, att_counts = get_initial_state(a, session)\n",
    "    count=0\n",
    "    accuracy=0\n",
    "    for i, token in enumerate(all_test_cases[:-5]):\n",
    "        lst =np.ones([1, 1])\n",
    "        token_id = map_token(word_to_id, token)\n",
    "        \n",
    "        if isinstance(token_id, tuple):\n",
    "            data = (np.array([[token_id[0]]]), np.array([[1]]), np.array([lst]), np.array([1]), np.array([1]))\n",
    "        else:\n",
    "            data = (np.array([[token_id]]), np.array([[1]]), np.array([lst]), np.array([1]), np.array([1]))\n",
    "        results, state, att_states, att_counts = run_network(map_token(word_to_id, token), state, att_states,\n",
    "                                                                     att_ids, att_counts)\n",
    "        root = BeamSearchTreeNode(map_token(word_to_id, all_test_cases[-1]),np.ones([1, 1]),\n",
    "                                          (state, att_states, att_counts), 1)\n",
    "        beam(root)\n",
    "        beam_search_recursive(root, 1)\n",
    "        path = find_path(root)[0]  # The most likely path\n",
    "        actual = [map_token(word_to_id, t) for t in all_test_cases[i + 1:i + 5 + 1]]\n",
    "\n",
    "        pred = \" \".join([inv_map[t].replace(\"\\n\", \"<newline>\") for t in path])\n",
    "        \n",
    "        act = []\n",
    "        for t in actual:\n",
    "            try:\n",
    "                act.append(inv_map[t[0]].replace(\"\\n\", \"<newline>\"))\n",
    "            except:\n",
    "                act.append(inv_map[t].replace(\"\\n\", \"<newline>\"))\n",
    "        act = ' '.join (act)\n",
    "        \n",
    "        print('-'*40)\n",
    "        print(\"Token(input): \", token.replace(\"\\n\", \"<newline>\"))\n",
    "        print(\"Predicted: \", pred)\n",
    "        print('Actual   : ', act)\n",
    "        count+=count+1\n",
    "        if pred == act:\n",
    "            accurate += 1\n",
    "    print(\"Accuracy: %f\" % (accuracy / count))\n",
    "#         results = session.run(evaluation, feed_dict)\n",
    "#         results_match = ''.join(str(results[1][0][0]))\n",
    "#         actual = [map_token(word_to_id, t) for t in all_test_cases[i + 1:i + 5 + 1]]\n",
    "#         act = \" \".join([inv_map[t[0]].replace(\"\\n\", \"<newline>\") for t in actual])\n",
    "#         print('=============')\n",
    "#         print('predict', inv_map[results[1][0][1]])\n",
    "#         print('real', act)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 어큐러시가 낮은이유 : \n",
    "### 적은데이터셋트로 훈련을했었고, 훈련이 더필요함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
